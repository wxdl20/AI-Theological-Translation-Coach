import streamlit as st
import json
import os
import random
import base64
import edge_tts
import asyncio
import re
import tempfile
import html
from dotenv import load_dotenv
from openai import OpenAI

# ==================== System Instruction ====================
# åŸºç¡€æ•™ç»ƒæŒ‡ä»¤ï¼ˆæ‰€æœ‰æ¨¡å¼å…±äº«ï¼‰
BASE_COACH_INSTRUCTION = """
You are a strict Reformed Theological Translation Consultant training Chinese students for cross-cultural missions (South Asia/Africa).
Your goal is to train students to translate Chinese (CUV) into precise ESV English, while equipping them with cultural sensitivity for KJV-loving mission fields.

**CORE EVALUATION LOGIC:**

1.  **Context is King (Theology):**
    * Evaluate based on the specific Bible Verse (e.g., Gen 17:7).
    * Distinguish between "Passable synonyms" and "Theological Precision".
    * *Example:* In Gen 15, "Cut (Karat)" is correct. In Gen 17, "Establish (HÄ“qÃ®m)" is better.

2.  **The "Missionary Bridge" (KJV Handling):**
    * Your target audience respects the KJV. If the user uses a **KJV term** (e.g., "Holy Ghost", "Charity", "Seed", "Quickened") instead of the ESV target:
    * **Status:** ğŸŸ¢ **GREEN (Pass)** or ğŸŸ¡ **YELLOW (Valid Variant)** - DO NOT FAIL THEM.
    * **Feedback:** Acknowledge the KJV validity for the mission field, but gently guide back to ESV for academic precision.
    * *Example:* "Valid KJV term. å·¥åœºè€ä¿¡å¾’å¸¸ç”¨ 'Holy Ghost'ï¼Œä½† ESV ä¸ºæ±‚æ¸…æ™°ä½¿ç”¨ 'Holy Spirit'ã€‚"

3.  **The "Anti-Chinglish" Filter (Chinese Habit):**
    * Strictly monitor for "Chinglish" errors where students translate Chinese characters literally.
    * **Status:** ğŸ”´ **RED (Fail)**.
    * *Example:* Translating "è‚‰ä½“" (Flesh/Sinful nature) as "Meat" or "Body".
    * *Example:* Translating "ç«‹çº¦" (Make/Cut covenant) as "Build a contract".

4.  **Traffic Light System (Summary):**
    * ğŸŸ¢ **GREEN (Pass):** Perfect ESV match OR Strong KJV variant.
    * ğŸŸ¡ **YELLOW (Warning):** Passable word but missed nuance / Archaic KJV term.
    * ğŸ”´ **RED (Fail):** Wrong meaning, Secular term (Contract), or Chinglish.

**FEEDBACK STYLE RULES (Crucial):**

* **Language:** Speak in **Chinese**, but keep Key Theological Terms in **English**.
* **Original Language:** ONLY cite Hebrew/Greek if it helps explain a nuanced distinction (e.g., distinguishing *Karat* vs *Qum*). Do NOT use it for simple vocabulary mistakes.
* **Anti-Redundancy:** The user sees the correct answer. Do NOT say "Correct answer is X". Instead, explain the **logic gap**.
    * *Bad:* "You said Make. The correct word is Establish."
    * *Good:* "è¿™é‡Œç”¨ Make ç¨æ˜¾è½¯å¼±ã€‚Gen 17 æ˜¯åœ¨ç¡®è®¤æ—§çº¦ï¼ŒåŸæ–‡ *HÄ“qÃ®m* å¼ºè°ƒ 'Establish' (åšç«‹) è€Œéæ–°ç«‹ã€‚"
    * *Good (Chinglish):* "ä¸è¦ç”¨ 'Meat'ã€‚ä¿ç½—ç¥å­¦ä¸­ï¼Œ'è‚‰ä½“'æŒ‡ç½ªæ€§ (Flesh)ï¼Œä¸æ˜¯èœå¸‚åœºçš„è‚‰ã€‚"

**COMPARISON-BASED COACHING (Core Function):**

You MUST compare the user's transcribed speech with the ESV target word-by-word and phrase-by-phrase.

1. **Precise Comparison:**
   * Identify EXACT differences: missing words, wrong word choice, word order, grammar errors.
   * Focus on the KEY TERM first, then sentence structure.

2. **Concise & Actionable Feedback:**
   * **Word Count:** Maximum 2 sentences (ideally 1 sentence). Be BRIEF but PRECISE.
   * **Focus on Improvement:** Don't just point out errors. Explain WHY the ESV choice is better and HOW to improve.
   * **Pattern Recognition:** If the error suggests a deeper issue (e.g., always using weak verbs), hint at the pattern.
   
3. **Examples of Good Feedback:**
   * *Bad (too long):* "You said 'make' but the correct answer is 'establish'. In Hebrew, the word HÄ“qÃ®m means to establish or confirm something that already exists, not to create something new. So you should use 'establish' instead of 'make'."
   * *Good (concise & actionable):* "ç”¨ 'Establish' æ›¿ä»£ 'Make'ã€‚è¿™é‡Œå¼ºè°ƒåšç«‹æ—§çº¦ï¼Œä¸æ˜¯æ–°ç«‹ã€‚"
   * *Good (pattern-focused):* "é¿å…é€šç”¨åŠ¨è¯ 'Give'ã€‚ç¥å­¦è¯­å¢ƒä¸­ï¼Œ'Present' æ›´ç²¾å‡†ï¼Œå¼ºè°ƒä¸»åŠ¨çŒ®ä¸Šã€‚"

4. **Feedback Priority:**
   * If KEY TERM is wrong â†’ Focus on theological precision.
   * If structure is wrong â†’ Focus on English syntax.
   * If both are wrong â†’ Focus on KEY TERM first.

**Output Format:**
Return a JSON object: 
{
  "status": "pass" | "warning" | "fail", 
  "user_said": "exact transcription from audio",
  "feedback": "Markdown in Chinese with THREE ultra-short lines: '### 1. ç¥å­¦æ ¸å¿ƒ (Theology)ï¼š...'; '### 2. æ¼”ç»è¡¨ç° (Delivery)ï¼š...'; '### 3. æˆé•¿èšç„¦ (Growth)ï¼š...'. Each line â‰¤ 16 Chinese characters, keep key theological terms in English."
}
"""

# æ¨¡å¼ç‰¹å®šçš„ç³»ç»ŸæŒ‡ä»¤
MODE_INSTRUCTIONS = {
    "ğŸ™ï¸ è®²å°å£è¯‘ (Pulpit)": """ä½ æ˜¯ä¸€ä½åœ¨è·¨æ–‡åŒ–å®£æ•™å·¥åœºæœä¾å¤šå¹´çš„**èµ„æ·±è®²å°å£è¯‘å¯¼å¸ˆ**ã€‚
é‡ç‚¹è¯„ä¼°ï¼š
1. **å¼ºåŠ¨è¯æ°”åŠ¿**: æ‹’ç»è½¯ç»µç»µçš„è¯ (å¦‚ Give vs Present)ã€‚
2. **è¯­éŸ³è¯­è°ƒ**: ç”¨è¯åŠ›åº¦å’Œæƒå¨æ„Ÿã€‚
3. **åä¸­å¼æ­é…**: ä¸¥ç¦ Chinglishã€‚
é£æ ¼ï¼šæ¿€æƒ…ã€ç›´æ¥ã€åƒè®²é“å­¦æ•™æˆã€‚""",
    
    "ğŸ« ç¥å­¦è¯¾å ‚ (Classroom)": """ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„**æ”¹é©å®—ç¥å­¦æ•™æˆ**ã€‚
é‡ç‚¹è¯„ä¼°ï¼š
1. **å¥æ³•é€»è¾‘**: è¿æ¥è¯ (For, Therefore) æ˜¯å¦å‡†ç¡®ã€‚
2. **æ•™ä¹‰å¾®è°ƒ**: ä¸¥é˜²ç¥å­¦é”™è¯¯ (å¦‚ Justify vs Make Righteous)ã€‚
é£æ ¼ï¼šå†·é™ã€å­¦æœ¯ã€å…³æ³¨é€»è¾‘é“¾ã€‚""",
    
    "ğŸ™ ç¥·å‘Š/çµä¿® (Devotional)": """ä½ æ˜¯ä¸€ä½**å±çµå¯¼å¸ˆ**ã€‚
é‡ç‚¹è¯„ä¼°ï¼š
1. **æƒ…æ„Ÿæ·±åº¦**: ä½¿ç”¨å¼ºçƒˆçš„å…³ç³»åŠ¨è¯ (Pants for vs Miss)ã€‚
2. **KJV äº²å’ŒåŠ›**: é¼“åŠ±ä½¿ç”¨ Thee/Thouã€‚
é£æ ¼ï¼šæ¸©æŸ”ã€æ•é”ã€å…³æ³¨å†…å¿ƒã€‚"""
}

def get_coach_instruction(mode):
    """æ ¹æ®æ¨¡å¼è¿”å›å®Œæ•´çš„ç³»ç»ŸæŒ‡ä»¤ï¼›mode å¿…é¡»æ¥è‡ªç•Œé¢ä¸‹æ‹‰æ¡†"""
    # è¿™é‡Œå‡è®¾ mode å·²ç»ç”±ç•Œé¢ selectbox ä¿è¯åˆæ³•ï¼Œä¸å†å¼ºåˆ¶å›é€€åˆ°è®²å°æ¨¡å¼
    mode_instruction = MODE_INSTRUCTIONS[mode]
    return BASE_COACH_INSTRUCTION + "\n\n**MODE-SPECIFIC FOCUS:**\n" + mode_instruction

# 1. é…ç½®ä¸åˆå§‹åŒ–
st.set_page_config(
    page_title="Pulpit Power AI", 
    page_icon="ğŸ™ï¸", 
    layout="centered",  # ç§»åŠ¨ç«¯å‹å¥½ï¼šå±…ä¸­å¸ƒå±€
    initial_sidebar_state="collapsed"  # é»˜è®¤æ”¶èµ·ä¾§è¾¹æ 
)

# è‡ªå®šä¹‰æ·±è‰²â€œæ”¹é©å®—ç¥å­¦é™¢â€é£æ ¼ä¸»é¢˜
CUSTOM_CSS = """
<style>
@import url('https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&family=Roboto:wght@300;400;500&display=swap');

html, body, [data-testid="stAppViewContainer"] {
  background-color: #0E1117;
  color: #E0E0E0;
  font-family: 'Roboto', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
}

/* ä¸­å¤®å­¦é™¢å¼å†…å®¹å®¹å™¨ */
.app-shell {
  max-width: 980px;
  margin: 0 auto;
  padding: 1.25rem 1.5rem 0.5rem 1.5rem;
}

.hero-title {
  font-family: 'Merriweather', 'Georgia', serif;
  font-size: 2.1rem;
  letter-spacing: 0.08em;
  text-transform: uppercase;
  color: #F8E8C2;
}

.hero-subtitle {
  font-size: 0.9rem;
  letter-spacing: 0.18em;
  text-transform: uppercase;
  color: rgba(221, 199, 142, 0.9);
  margin-top: 0.25rem;
}

.hero-rule {
  border: none;
  height: 1px;
  margin-top: 0.9rem;
  margin-bottom: 0.4rem;
  background: linear-gradient(90deg, transparent, rgba(212, 175, 55, 0.8), transparent);
}

[data-testid="stSidebar"] {
  background: #11141c;
  border-right: 1px solid rgba(212, 175, 55, 0.25);
}

[data-testid="stSidebar"] h3, [data-testid="stSidebar"] p {
  font-family: 'Merriweather', 'Georgia', serif;
}

h1, h2, h3, h4 {
  font-family: 'Merriweather', 'Georgia', 'Times New Roman', serif;
  color: #F5E6C8;
}

/* éšè—é»˜è®¤ Header / Footer */
header[data-testid="stHeader"] {
  display: none;
}
footer {
  visibility: hidden;
}

/* æŒ‰é’®ï¼šé»‘é‡‘æ¸å˜ */
.stButton > button {
  background: linear-gradient(135deg, #1b1f2a, #D4AF37);
  color: #0E1117;
  border-radius: 999px;
  border: 1px solid #D4AF37;
  padding: 0.5rem 1.25rem;
  font-weight: 600;
  letter-spacing: 0.03em;
}
.stButton > button:hover {
  box-shadow: 0 0 18px rgba(212, 175, 55, 0.45);
  transform: translateY(-1px);
}

/* è¾“å…¥åŒºï¼šç£¨ç ‚ç»ç’ƒæ•ˆæœ */
[data-testid="stFileUploader"], [data-testid="stAudioInput"] {
  background: rgba(18, 22, 33, 0.8);
  border-radius: 12px;
  border: 1px solid rgba(212, 175, 55, 0.35);
  box-shadow: 0 0 25px rgba(0, 0, 0, 0.6);
  backdrop-filter: blur(10px);
}

.stTextInput > div > div > input {
  background-color: rgba(15, 18, 28, 0.9);
  border-radius: 8px;
  border: 1px solid rgba(212, 175, 55, 0.4);
}

/* é¢˜ç›®æ‚¬æµ®å¡ç‰‡ */
.sermon-card {
  background: radial-gradient(circle at top left, rgba(212, 175, 55, 0.18), rgba(9, 11, 17, 0.98));
  border-left: 4px solid #D4AF37;
  border-radius: 14px;
  padding: 1.25rem 1.5rem;
  margin-top: 0.5rem;
  box-shadow: 0 22px 46px rgba(0, 0, 0, 0.85);
}
.sermon-card-ref {
  font-size: 0.85rem;
  letter-spacing: 0.12em;
  color: rgba(244, 231, 186, 0.9);
  text-transform: uppercase;
}
.sermon-card-text {
  font-size: 1.3rem;
  margin-top: 0.4rem;
}

/* åé¦ˆå®¹å™¨ */
.feedback-box {
  border-radius: 14px;
  padding: 1rem 1.15rem;
  margin-top: 0.75rem;
  background: rgba(10, 13, 20, 0.96);
  border: 1px solid rgba(255, 255, 255, 0.06);
}
.feedback-title {
  font-weight: 700;
  margin-bottom: 0.35rem;
}
.feedback-body {
  font-size: 0.95rem;
  line-height: 1.5;
  white-space: pre-wrap;
}
.feedback-pass {
  border-color: #2ecc71;
  box-shadow: 0 0 14px rgba(46, 204, 113, 0.35);
}
.feedback-warning {
  border-color: #f1c40f;
  box-shadow: 0 0 14px rgba(241, 196, 15, 0.3);
}
.feedback-fail {
  border-color: #e74c3c;
  box-shadow: 0 0 18px rgba(231, 76, 60, 0.45);
}

/* æŠ˜å é¢æ¿ / Tabs å¾®è°ƒ */
[data-testid="stExpander"] {
  border-radius: 12px;
  border: 1px solid rgba(212, 175, 55, 0.4);
  background: rgba(12, 15, 24, 0.95);
}
[data-testid="stTabs"] > div > div {
  background: transparent;
}
[data-baseweb="tab-list"] {
  border-bottom: 1px solid rgba(212, 175, 55, 0.4);
}

.app-footer {
  font-size: 0.8rem;
  color: rgba(224, 224, 224, 0.6);
  text-align: center;
  margin-top: 1.5rem;
}
</style>
"""

st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

# é¡¶éƒ¨â€œç¥å­¦é™¢â€å¼æŠ¬å¤´åŒºåŸŸ
st.markdown(
    """
    <div class="app-shell">
        <div class="hero-title">AI ç¥å­¦å£è¯‘æ•™ç»ƒ</div>
        <div class="hero-subtitle">Reformed Theological Translation Studio</div>
        <hr class="hero-rule" />
    </div>
    """,
    unsafe_allow_html=True,
)

# åç»­ä¸»ä½“å†…å®¹ä¹ŸåŒ…è£¹åœ¨ app-shell ä¸­ï¼Œè¥é€ å±…ä¸­å­¦é™¢æ„Ÿ
st.markdown('<div class="app-shell">', unsafe_allow_html=True)
load_dotenv()

# API é…ç½® (ä¸å·¥å‚ä¸€è‡´)
API_KEY = os.getenv("GEMINI_API_KEY")
BASE_URL = os.getenv("GEMINI_BASE_URL", "https://api.laozhang.ai/v1")
MODEL_NAME = "gemini-2.5-flash"

if not API_KEY:
    st.error("âŒ æœªæ‰¾åˆ° API Keyï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")
    st.stop()

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

# 2. åŠ è½½æ•°æ®å‡½æ•°
@st.cache_data
def load_library():
    data_dir = "assets/bible_data"
    library = {}
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
        return library
    
    # è¿‡æ»¤æ‰ blueprint æ–‡ä»¶ï¼ˆè¿™äº›æ˜¯ç»™å·¥å‚è„šæœ¬ç”¨çš„ï¼Œä¸æ˜¯ç»™ç”¨æˆ·çš„ï¼‰
    files = [f for f in os.listdir(data_dir) 
             if f.endswith(".json") and not f.startswith("blueprint")]
    for f in files:
        book_name = f.replace(".json", "")
        with open(os.path.join(data_dir, f), "r", encoding="utf-8") as file:
            library[book_name] = json.load(file)
    return library

library = load_library()

# ==================== Helper Functions ====================

def get_audio_mime_type(audio_data):
    """Get MIME type for audio data (handles both audio_input and file_uploader)"""
    if hasattr(audio_data, 'type') and audio_data.type:
        return audio_data.type
    elif hasattr(audio_data, 'name'):
        # File uploader - determine from file extension
        file_ext = audio_data.name.split('.')[-1].lower()
        mime_map = {
            'wav': 'audio/wav',
            'mp3': 'audio/mpeg',
            'm4a': 'audio/mp4',
            'webm': 'audio/webm',
            'ogg': 'audio/ogg'
        }
        return mime_map.get(file_ext, 'audio/wav')
    else:
        return "audio/webm"

def generate_audio_sync(text, filename='esv_demo.mp3', voice='en-US-ChristopherNeural', rate='-10%'):
    """Generate audio synchronously using edge_tts and save to cache directory"""
    async def _gen():
        try:
            if not text:
                raise ValueError("Text is empty")
            
            # æ¸…ç†ç‰¹æ®Šç¬¦å·ï¼ˆMarkdownæ ¼å¼ç¬¦å·ï¼‰ï¼Œé¿å…TTSè¯»å‡ºè¿™äº›ç¬¦å·
            clean_text = str(text)
            # ç§»é™¤ Markdown æ ¼å¼ç¬¦å·ï¼š* _ ` [ ] ( ) # ç­‰
            clean_text = re.sub(r'[*_`\[\]()#]', '', clean_text)
            # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
            clean_text = re.sub(r'\s+', ' ', clean_text).strip()
            
            if not clean_text:
                raise ValueError("Text contains no valid characters after cleaning")
            
            # Set locale to UTF-8 to avoid encoding issues
            os.environ['LC_ALL'] = 'C.UTF-8'
            os.environ['LANG'] = 'C.UTF-8'
            
            communicate = edge_tts.Communicate(text=clean_text, voice=voice, rate=rate)
            audio_data = b""
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio_data += chunk["data"]
            
            # Save to cache directory (temp directory)
            cache_dir = os.path.join(tempfile.gettempdir(), "pulpit_power_cache")
            os.makedirs(cache_dir, exist_ok=True)
            output_path = os.path.join(cache_dir, filename)
            with open(output_path, 'wb') as f:
                f.write(audio_data)
            
            return output_path
        except Exception as e:
            # Clean error message
            try:
                clean_error = str(e).encode('utf-8', errors='replace').decode('utf-8')
                error_msg = clean_error
            except:
                error_msg = "Unknown error"
            raise Exception(f"Audio generation failed: {error_msg}")
    
    # Run async function in sync wrapper
    return asyncio.run(_gen())

def generate_chinese_audio_sync(text, filename='chinese_phrase.mp3'):
    """Generate Chinese audio using edge_tts"""
    return generate_audio_sync(text, filename=filename, voice='zh-CN-XiaoxiaoNeural', rate='-5%')

# 4. AI è¯„ä¼°å‡½æ•°ï¼ˆæ”¯æŒéŸ³é¢‘è¾“å…¥ï¼‰
def evaluate_translation(audio_data, card, mode):
    """
    è¯„ä¼°ç¿»è¯‘ï¼šä½¿ç”¨éŸ³é¢‘è¾“å…¥ï¼ŒAI ä¼šè½¬å½•å¹¶è¯„åˆ†
    mode: è®­ç»ƒæ¨¡å¼ï¼ˆè®²å°/è¯¾å ‚/ç¥·å‘Šï¼‰
    """
    # æ„å»ºç”¨æˆ·æç¤ºè¯ï¼ˆåŒ…å«å½“å‰æ¨¡å¼åŠå…¶ä¸‰å¤§è¯„ä¼°é‡ç‚¹ï¼‰
    user_prompt = f"""Here is the audio recording. The user will translate this Chinese phrase to English.

**Context:**
- Reference: {card.get('ref', 'N/A')}
- Chinese phrase: "{card.get('phrase_cn', 'N/A')}"
- Full context: "{card.get('sentence_context', 'N/A')}"
- Expected ESV target: "{card.get('phrase_en', 'N/A')}"
- Key term to focus on: "{card.get('key_term', 'N/A')}"
- Trap to avoid: {card.get('trap', [])}

**Mode & Focus (VERY IMPORTANT):**
- Current mode: {mode}
- Mode-specific focus in Chinese (three bullet points you MUST follow exactly, in order):
{MODE_INSTRUCTIONS[mode]}

**Your task:**
1. Listen to the audio and transcribe EXACTLY what you hear (or "NO_AUDIO" if you hear nothing).
2. **Compare word-by-word:** Your transcription vs ESV target "{card.get('phrase_en', 'N/A')}".
   - Identify missing words, wrong word choices, word order issues.
   - Pay special attention to the KEY TERM: "{card.get('key_term', 'N/A')}".
3. **Evaluate using theological coach rules** from system instruction.
4. **Generate concise feedback:** Compare ESV vs user's speech, explain WHY the difference matters, and HOW to improve. 
   Your feedback MUST be structured into THREE ultra-short lines in Chinese, each line corresponding to ONE bullet point of the current mode:
   - Line 1 = ç¥å­¦æ ¸å¿ƒ (Theology) â†’ Comment on the FIRST bullet of the current mode.
   - Line 2 = æ¼”ç»è¡¨ç° (Delivery) â†’ Comment on the SECOND bullet of the current mode.
   - Line 3 = æˆé•¿èšç„¦ (Growth) â†’ Comment on the THIRD bullet of the current mode, giving ONE concrete next-step tip.

**CRITICAL: Comparison-Based Feedback**
- Compare: "User said: [transcription]" vs "ESV: {card.get('phrase_en', 'N/A')}"
- Focus on KEY TERM accuracy first, then sentence structure.
- Be BRIEF but PRECISE. Focus on improvement, not just error listing.
- Example: "ç”¨ 'Establish' æ›¿ä»£ 'Make'ã€‚è¿™é‡Œå¼ºè°ƒåšç«‹æ—§çº¦ï¼Œä¸æ˜¯æ–°ç«‹ã€‚"

**Output JSON format:**
{{
  "status": "pass/warning/fail",
  "user_said": "exact transcription or 'NO_AUDIO'",
  "feedback": "Generate a Markdown-formatted coaching comment in Chinese. Structure it strictly as follows:

**1. ğŸ¯ è¯Šæ–­ (Diagnosis):** Identify the specific gap. Was it a weak verb? A theological drift? Or a lack of rhythm? (Max 1 sentence).

**2. ğŸ’¡ ä¿®æ­£ (Correction):** Provide the specific fix based on the current Mode. 
- If Pulpit Mode: Focus on power ('Use Proclaim!'). 
- If Classroom Mode: Focus on logic ('Add Therefore!'). 
- If Prayer Mode: Focus on emotion ('Use Pant for!').

**3. ğŸ§  æ´è§ (Insight):** A brief, memorable 'Theological Rule of Thumb' or 'Mission Field Tip'. (e.g., 'ç¥çš„ä¸»æƒä¸å®¹è¢«åŠ¨è¯­æ€', or 'å·¥åœºä¸Š KJV çš„ Thee æ›´æ˜¾äº²å¯†').

**Style Constraint:** - Professional, authoritative, yet encouraging.
- Total length: Keep it under 150 Chinese characters total.
- Use bolding for key terms."
}}

âš ï¸ If audio is SILENT/EMPTY: user_said must be "NO_AUDIO" and status must be "fail"
âš ï¸ user_said MUST be what you actually HEAR, not the expected answer
âš ï¸ feedback MUST compare ESV vs user_said and provide actionable improvement advice

Output ONLY valid JSON object."""
    
    try:
        if not audio_data:
            return {"status": "fail", "user_said": "NO_AUDIO", "feedback": "æœªæ£€æµ‹åˆ°éŸ³é¢‘è¾“å…¥"}
        
        # è¯»å–éŸ³é¢‘å­—èŠ‚
        audio_bytes = audio_data.read()
        
        if len(audio_bytes) == 0:
            return {"status": "fail", "user_said": "NO_AUDIO", "feedback": "éŸ³é¢‘æ–‡ä»¶ä¸ºç©º"}
        
        # æ ¹æ®æ¨¡å¼è·å–ç³»ç»ŸæŒ‡ä»¤
        coach_instruction = get_coach_instruction(mode)
        
        # æ ¹æ® use_proxy è®¾ç½®åˆ›å»º client
        if st.session_state.use_proxy:
            # ä½¿ç”¨ laozhang.ai ä»£ç†
            api_client = OpenAI(
                api_key=API_KEY,
                base_url="https://api.laozhang.ai/v1"
            )
            
            # Convert audio to base64
            audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
            audio_mime_type = get_audio_mime_type(audio_data)
            
            # Call via OpenAI-compatible API with system instruction
            response = api_client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {
                        "role": "system",
                        "content": coach_instruction
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": user_prompt},
                            {
                                "type": "input_audio",
                                "input_audio": {
                                    "data": audio_base64,
                                    "format": audio_mime_type.split('/')[-1]
                                }
                            }
                        ]
                    }
                ]
            )
            
            response_text = response.choices[0].message.content
        else:
            # ä½¿ç”¨ç›´æ¥ Google APIï¼ˆéœ€è¦ google.generativeaiï¼‰
            import google.generativeai as genai
            genai.configure(api_key=API_KEY)
            
            # Try gemini-2.0-flash-exp first, fallback to 1.5-pro, then 2.5-flash
            try:
                model = genai.GenerativeModel('gemini-2.0-flash-exp', system_instruction=coach_instruction)
            except:
                try:
                    model = genai.GenerativeModel('gemini-1.5-pro', system_instruction=coach_instruction)
                except:
                    model = genai.GenerativeModel('gemini-2.5-flash')
            
            # Prepare audio file
            audio_mime_type = get_audio_mime_type(audio_data)
            audio_file = {
                "mime_type": audio_mime_type,
                "data": audio_bytes
            }
            
            # Call Gemini API
            response = model.generate_content([user_prompt, audio_file])
            response_text = response.text
        
        # Parse JSON response
        if not isinstance(response_text, str):
            response_text = str(response_text)
        response_text = response_text.strip()
        
        # Remove markdown code blocks if present
        if response_text.startswith("```"):
            response_text = response_text.split("```")[1]
            if response_text.startswith("json"):
                response_text = response_text[4:]
        response_text = response_text.strip()
        
        result = json.loads(response_text)
        
        # Normalize status
        if 'status' in result:
            result['status'] = result['status'].lower()
        
        return result
        
    except Exception as e:
        # Clean error message
        try:
            error_msg = str(e).encode('utf-8', errors='replace').decode('utf-8')
        except:
            error_msg = "Unknown error"
        return {"status": "fail", "user_said": "ERROR", "feedback": f"AI è¿æ¥é”™è¯¯: {error_msg}"}

# 5. ç•Œé¢å¸ƒå±€ (UI)

# --- åˆå§‹åŒ– Session State ---
if 'current_index' not in st.session_state:
    st.session_state.current_index = 0
if 'selected_book' not in st.session_state:
    st.session_state.selected_book = None
if 'book_data' not in st.session_state:
    st.session_state.book_data = []
if 'feedback' not in st.session_state:
    st.session_state.feedback = None
if 'use_proxy' not in st.session_state:
    st.session_state.use_proxy = True  # é»˜è®¤ä½¿ç”¨ laozhang ä¸­è½¬æœåŠ¡
if 'selected_mode' not in st.session_state:
    st.session_state.selected_mode = list(MODE_INSTRUCTIONS.keys())[0]  # é»˜è®¤ç¬¬ä¸€ä¸ªæ¨¡å¼

# --- ä¾§è¾¹æ ï¼šè®¾ç½®ï¼ˆç¨³å¥ç‰ˆï¼‰---
with st.sidebar:
    st.markdown("### ğŸ›¡ï¸ Pulpit Power")
    
    # é€»è¾‘ 1: åŸºç¡€æ•°æ®ä¿æŠ¤
    if not library:
        st.warning("âš ï¸ åº“ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ assets è·¯å¾„")
        # ä¸è¦åœ¨è¿™é‡Œç”¨ st.stop()ï¼Œå¦åˆ™ä¾§è¾¹æ å°±æ­»æ‰äº†
        st.info("å½“å‰è·¯å¾„: " + os.getcwd()) # è°ƒè¯•ç”¨
    else:
        book_options = list(library.keys())
        
        # é€»è¾‘ 2: åˆå§‹åŒ– Session State (é˜²æ­¢ KeyError)
        if 'selected_book' not in st.session_state:
            st.session_state.selected_book = book_options[0]
        if 'current_index' not in st.session_state:
            st.session_state.current_index = 0
            
        # é€»è¾‘ 3: ä¹¦å·é€‰æ‹©å™¨ (å»æ‰å¤æ‚çš„ index è®¡ç®—ï¼Œæ”¹ç”¨ç®€å•é€»è¾‘)
        # æˆ‘ä»¬ç”¨ on_change å›è°ƒæ¥å¤„ç†é‡ç½®ï¼Œè€Œä¸æ˜¯åœ¨ä¸»å¾ªç¯é‡Œ rerun
        def on_book_change():
            st.session_state.current_index = 0
            st.session_state.feedback = None
            # è¿™é‡Œçš„ book_selector æ˜¯ä¸‹é¢ selectbox çš„ key
            st.session_state.selected_book = st.session_state.book_selector

        selected_book = st.selectbox(
            "ğŸ“š ä¹¦å·",
            options=book_options,
            key="book_selector",
            on_change=on_book_change
        )
        
        # é€»è¾‘ 4: ç¡®ä¿ book_data å§‹ç»ˆæœ‰æ•ˆ
        book_data = library.get(st.session_state.selected_book, [])
        
        # é€»è¾‘ 5: æ¨¡å¼é€‰æ‹©
        mode_options = list(MODE_INSTRUCTIONS.keys())
        selected_mode = st.selectbox(
            "ğŸ¯ æ¨¡å¼",
            options=mode_options,
            key="selected_mode" # ç›´æ¥ç»‘å®šåˆ° session_state
        )
        
        # è¿›åº¦æ¡
        if book_data:
            st.markdown("---")
            st.caption(f"è¿›åº¦: {st.session_state.current_index + 1} / {len(book_data)}")
            st.progress((st.session_state.current_index + 1) / len(book_data))
# --- ä¸»ç•Œé¢ï¼šè®­ç»ƒåŒºï¼ˆç§»åŠ¨ç«¯ä¼˜åŒ–ï¼‰---

# --- 1. æ•°æ®åŒæ­¥ä¿éšœ ---
# æ£€æŸ¥ book_data æ˜¯å¦ä¸ºç©ºï¼Œæˆ–è€…æ˜¯å¦ä¸å½“å‰é€‰ä¸­çš„ä¹¦å·ä¸åŒ¹é…
if not st.session_state.get('book_data') or st.session_state.get('last_loaded_book') != st.session_state.selected_book:
    # å¼ºåˆ¶é‡æ–°ä» library åŠ è½½
    st.session_state.book_data = library.get(st.session_state.selected_book, [])
    st.session_state.last_loaded_book = st.session_state.selected_book
    st.session_state.current_index = 0  # ç¡®ä¿ç´¢å¼•é‡ç½®

# --- 2. è·å–å½“å‰é¢˜ç›®å¡ç‰‡ (ç¨³å¥ç‰ˆ) ---
book_data = st.session_state.book_data

if book_data and 0 <= st.session_state.current_index < len(book_data):
    current_card = book_data[st.session_state.current_index]
else:
    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ•°æ®ï¼Œç»™å‡ºä¸€ä¸ªå‹å¥½çš„æç¤ºè€Œä¸æ˜¯ç›´æ¥ stop
    st.warning(f"âš ï¸ æ­£åœ¨å°è¯•åŠ è½½ {st.session_state.selected_book} çš„æ•°æ®...")
    if not library:
        st.error("âŒ ä¸¥é‡é”™è¯¯ï¼šå†…å­˜ä¸­çš„ library ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ï¼")
    st.rerun() # å¼ºåˆ¶åˆ·æ–°ä¸€æ¬¡ä»¥åŒæ­¥çŠ¶æ€

# é¡¶éƒ¨å¯¼èˆªæ ï¼ˆå­¦é™¢é£å¯¼èˆªï¼‰
col_title, col_nav = st.columns([3, 1])
with col_title:
    ref_text = current_card.get('ref', 'No Ref')
    st.markdown(f"**{st.session_state.selected_book}** {ref_text}")
with col_nav:
    nav_col1, nav_col2 = st.columns(2)
    with nav_col1:
        if st.session_state.current_index > 0:
            # ä½¿ç”¨æ›´å†…æ•›çš„ä¹¦ç­¾å¼ç®­å¤´
            if st.button("â®", use_container_width=True, key="prev_btn"):
                st.session_state.current_index -= 1
                st.session_state.feedback = None
                st.rerun()
    with nav_col2:
        if st.session_state.current_index < len(book_data) - 1:
            if st.button("â¯", use_container_width=True, key="next_btn"):
                st.session_state.current_index += 1
                st.session_state.feedback = None
                st.rerun()

# 1. é¢˜ç›®å¡ç‰‡ï¼šæ‚¬æµ®"è®²ç« å¡ç‰‡"é£æ ¼ï¼ˆé»˜è®¤ä¸æš´éœ²ä¸­æ–‡åŸæ–‡ï¼‰
st.markdown(
    f"""
    <div class="sermon-card">
        <div class="sermon-card-ref">{st.session_state.selected_book} Â· {current_card.get('ref', 'No Ref')}</div>
    </div>
    """,
    unsafe_allow_html=True,
)

# ä¸­æ–‡éŸ³é¢‘æ’­æ”¾ï¼ˆä¼˜å…ˆè®­ç»ƒ"å¬è¯‘"ï¼‰
try:
    safe_ref = re.sub(r'[^\x20-\x7E]', '_', current_card.get('ref', 'demo'))
    chinese_audio_filename = f"chinese_{safe_ref}.mp3"
    phrase_cn = current_card.get('phrase_cn', '')
    if phrase_cn:
        chinese_audio_file = generate_chinese_audio_sync(phrase_cn, chinese_audio_filename)
        if chinese_audio_file and os.path.exists(chinese_audio_file):
            st.audio(chinese_audio_file, format='audio/mp3')
            st.caption("ğŸ§ ä¸­æ–‡åŸæ–‡éŸ³é¢‘")
except Exception as e:
    st.caption("âš ï¸ éŸ³é¢‘ç”Ÿæˆä¸­...")

# ä¸­æ–‡åŸæ–‡æŠ˜å æ˜¾ç¤ºï¼Œä¼˜å…ˆè®­ç»ƒ"å¬è¯‘"è€Œé"çœ‹è¯‘"
phrase_cn = current_card.get('phrase_cn', 'æš‚æ— ä¸­æ–‡åŸæ–‡')
if phrase_cn:
    with st.expander("ğŸ“œ æŸ¥çœ‹ä¸­æ–‡åŸæ–‡", expanded=False):
        st.markdown(phrase_cn)

# 2. éŸ³é¢‘è¾“å…¥åŒºï¼ˆç§»åŠ¨ç«¯ä¼˜åŒ–ï¼‰
st.markdown("---")
tab1, tab2 = st.tabs(["ğŸ™ï¸ å½•éŸ³", "ğŸ“ ä¸Šä¼ "])

audio_data = None

with tab1:
    audio_data = st.audio_input("ç‚¹å‡»å½•éŸ³", label_visibility="visible")

with tab2:
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ éŸ³é¢‘",
        type=['wav', 'mp3', 'm4a', 'webm', 'ogg']
    )
    if uploaded_file is not None:
        audio_data = uploaded_file
        file_ext = uploaded_file.name.split('.')[-1].lower() if hasattr(uploaded_file, 'name') else 'wav'
        mime_map = {
            'wav': 'audio/wav',
            'mp3': 'audio/mpeg',
            'm4a': 'audio/mp4',
            'webm': 'audio/webm',
            'ogg': 'audio/ogg'
        }
        audio_format = mime_map.get(file_ext, 'audio/wav')
        st.audio(uploaded_file, format=audio_format)

# 3. æäº¤æŒ‰é’®ï¼ˆç§»åŠ¨ç«¯ä¼˜åŒ–ï¼‰
st.markdown("---")
if audio_data is not None:
    if st.button("ğŸš€ æäº¤è¯„ä¼°", type="primary", use_container_width=True):
        with st.spinner("ğŸ¤– AI åˆ†æä¸­..."):
            result = evaluate_translation(audio_data, current_card, st.session_state.selected_mode)
            st.session_state.feedback = result
            st.rerun()
else:
    st.caption("ğŸ’¡ è¯·å…ˆå½•éŸ³æˆ–ä¸Šä¼ éŸ³é¢‘")

# 4. åé¦ˆæ˜¾ç¤ºåŒºï¼ˆè‡ªå®šä¹‰å­¦æœ¯é£æ ¼ï¼‰
if st.session_state.feedback:
    fb = st.session_state.feedback
    status = fb.get('status', 'fail').lower()
    user_said = fb.get('user_said', 'N/A')
    
    st.markdown("---")
    
    # æ˜¾ç¤ºç”¨æˆ·å®é™…è¯´çš„å†…å®¹
    if user_said and user_said != 'N/A' and user_said.upper() != 'NO_AUDIO':
        with st.container(border=True):
            st.markdown(f"**ğŸ¤ æ‚¨çš„ç¿»è¯‘:** {user_said}")
    
    # è‡ªå®šä¹‰åé¦ˆå¡ç‰‡ï¼ˆæ›¿ä»£ st.success / st.warning / st.errorï¼‰
    status_meta = {
        "pass":  {"cls": "feedback-pass",    "title": "âœ… ç¥å­¦è¯„ä¼°ï¼šé€šè¿‡"},
        "warning": {"cls": "feedback-warning", "title": "ğŸŸ¡ ç¥å­¦è¯„ä¼°ï¼šéœ€ç•™æ„"},
        "fail": {"cls": "feedback-fail",    "title": "ğŸ”´ ç¥å­¦è¯„ä¼°ï¼šéœ€é‡ç‚¹ä¿®æ­£"},
    }
    meta = status_meta.get(status, status_meta["fail"])
    raw_fb = fb.get("feedback", "")
    safe_fb = html.escape(str(raw_fb))
    feedback_html = f"""
    <div class="feedback-box {meta['cls']}">
        <div class="feedback-title">{meta['title']}</div>
        <div class="feedback-body">{safe_fb}</div>
    </div>
    """
    st.markdown(feedback_html, unsafe_allow_html=True)
    
    # 5. ç­”æ¡ˆæ­æ™“ä¸è§£æï¼ˆç§»åŠ¨ç«¯ä¼˜åŒ–ï¼šå•åˆ—å¸ƒå±€ï¼‰
    with st.expander("ğŸ” æŸ¥çœ‹è§£æ", expanded=False):
        # æ ‡å‡†å‘éŸ³ï¼ˆé¡¶éƒ¨ï¼‰
        try:
            safe_ref = re.sub(r'[^\x20-\x7E]', '_', current_card.get('ref', 'demo'))
            audio_filename = f"esv_demo_{safe_ref}.mp3"
            phrase_en = current_card.get('phrase_en', '')
            if phrase_en:
                generated_file = generate_audio_sync(phrase_en, audio_filename)
                if generated_file and os.path.exists(generated_file):
                    st.audio(generated_file)
                    st.caption("ğŸ§ æ ‡å‡†å‘éŸ³")
        except:
            pass
        
        # ç›®æ ‡ç­”æ¡ˆ
        phrase_en = current_card.get('phrase_en', 'æš‚æ— ç›®æ ‡ç­”æ¡ˆ')
        if phrase_en:
            st.markdown("**ğŸ¯ ç›®æ ‡ç­”æ¡ˆ:**")
            st.info(f"{phrase_en}")
        
        # å®Œæ•´ä¸Šä¸‹æ–‡
        sentence_context = current_card.get('sentence_context', '')
        if sentence_context:
            st.markdown("**ğŸ“– å®Œæ•´ä¸Šä¸‹æ–‡:**")
            st.caption(f"{sentence_context}")
        
        # å…³é”®è¯å’Œé™·é˜±
        col_key, col_trap = st.columns(2)
        with col_key:
            key_term = current_card.get('key_term', '')
            if key_term:
                st.markdown("**ğŸ”‘ å…³é”®è¯:**")
                st.code(key_term, language=None)
        with col_trap:
            trap = current_card.get('trap', [])
            if trap:
                st.markdown("**ğŸª¤ é™·é˜±:**")
                if isinstance(trap, list):
                    st.caption(", ".join(trap) if trap else "æ— ")
                else:
                    st.caption(str(trap))
        
        # è§£æè¯´æ˜
        nuance_note = current_card.get('nuance_note', '')
        if nuance_note:
            st.markdown("**ğŸ’¡ è§£æ:**")
            st.markdown(f"{nuance_note}")

# é¡µè„šï¼ˆå­¦é™¢é£æ ·å¼ï¼‰
st.markdown(
    '<div class="app-footer">Reformed Theological Translation Lab Â· Powered by Gemini & laozhang.ai</div>',
    unsafe_allow_html=True,
)

# å…³é—­ app-shell å®¹å™¨
st.markdown("</div>", unsafe_allow_html=True)